{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raulv\\AppData\\Local\\Temp\\ipykernel_13872\\986121327.py:30: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver= webdriver.Chrome(\"chromedrive\",options = options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs/search?keywords=Machine%20Learning&location=Santiago%20Metropolitan%20Region%20Chile&geoId=104555257&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\n"
     ]
    }
   ],
   "source": [
    "job_name = \"Machine Learning\"\n",
    "country_name = \"Santiago Metropolitan Region Chile\"\n",
    "job_url =\"\";\n",
    "for item in job_name.split(\" \"):\n",
    "    if item != job_name.split(\" \")[-1]:\n",
    "        job_url = job_url + item + \"%20\"\n",
    "    else:\n",
    "        job_url = job_url + item\n",
    "\n",
    "country_url =\"\";\n",
    "for item in country_name.split(\" \"):\n",
    "    if item != country_name.split(\" \")[-1]:\n",
    "        country_url = country_url + item + \"%20\"\n",
    "    else:\n",
    "        country_url = country_url + item\n",
    "\n",
    "url = f\"https://www.linkedin.com/jobs/search?keywords={job_url}&location={country_url}&geoId=104555257&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\"\n",
    "# Creating a webdriver instance\n",
    "options = webdriver.ChromeOptions()\n",
    "#All are optional\n",
    "# Agrega la opcion de que se quede abierta la pagina\n",
    "# options.add_experimental_option(\"detach\", True)\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_argument(\"--disable-Advertisement\")\n",
    "options.add_argument(\"--disable-popup-blocking\")\n",
    "options.add_argument(\"start-maximized\")\n",
    "\n",
    "driver= webdriver.Chrome(\"chromedrive\",options = options)\n",
    "# Opening the url we have just defined in our browser\n",
    "driver.get(url)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "#We find how many jobs are offered.\n",
    "jobs_num = driver.find_element(By.CSS_SELECTOR,\"h1>span\").get_attribute(\"innerText\")\n",
    "if len(jobs_num.split(',')) > 1:\n",
    "    jobs_num = int(jobs_num.split(',')[0])*1000\n",
    "else:\n",
    "    jobs_num = int(jobs_num)\n",
    "\n",
    "jobs_num   = int(jobs_num)\n",
    "print(jobs_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current at:  120 Percentage at:  101.68067226890756 %\r"
     ]
    }
   ],
   "source": [
    "#We create a while loop to browse all jobs. \n",
    "i = 2\n",
    "while i <= int(jobs_num/2)+1:\n",
    "    #We keep scrollind down to the end of the view.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    i = i + 1\n",
    "    print(\"Current at: \", i, \"Percentage at: \", ((i+1)/(int(jobs_num/2)+1))*100, \"%\",end=\"\\r\")\n",
    "    try:\n",
    "        #We try to click on the load more results buttons in case it is already displayed.\n",
    "        infinite_scroller_button = driver.find_element(By.XPATH, \".//button[@aria-label='See more jobs']\")\n",
    "        infinite_scroller_button.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        #If there is no button, there will be an error, so we keep scrolling down.\n",
    "        time.sleep(0.1)\n",
    "        pass\n",
    "#We get a list containing all jobs that we have found.\n",
    "job_lists = driver.find_element(By.CLASS_NAME,\"jobs-search__results-list\")\n",
    "jobs = job_lists.find_elements(By.TAG_NAME,\"li\") # return a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We declare void list to keep track of all obtaind data.\n",
    "job_title_list = []\n",
    "company_name_list = []\n",
    "location_list = []\n",
    "date_list = []\n",
    "job_link_list = []\n",
    "\n",
    "#We loof over every job and obtain all the wanted info.\n",
    "for job in jobs:\n",
    "    #job_title\n",
    "    job_title = job.find_element(By.CSS_SELECTOR,\"h3\").get_attribute(\"innerText\")\n",
    "    job_title_list.append(job_title)\n",
    "    \n",
    "    #company_name\n",
    "    company_name = job.find_element(By.CSS_SELECTOR,\"h4\").get_attribute(\"innerText\")\n",
    "    company_name_list.append(company_name)\n",
    "    \n",
    "    #location\n",
    "    location = job.find_element(By.CSS_SELECTOR,\"div>div>span\").get_attribute(\"innerText\")\n",
    "    location_list.append(location)\n",
    "    \n",
    "    #date\n",
    "    date = job.find_element(By.CSS_SELECTOR,\"div>div>time\").get_attribute(\"datetime\")\n",
    "    date_list.append(date)\n",
    "    \n",
    "    #job_link\n",
    "    job_link = job.find_element(By.CSS_SELECTOR,\"a\").get_attribute(\"href\")\n",
    "    job_link_list.append(job_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(job_title_list,company_name_list,\n",
    " location_list,job_link_list,\n",
    " date_list)),\n",
    " columns =['job_title', 'company_name',\n",
    " 'company_location','Job_link',\n",
    " 'post_date'])\n",
    "# Storing the data to csv file\n",
    "df.to_csv('job_offers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11ec388f491b3bc704f232a39012a26913ad6bfa322b962327eb6d255c011f39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
